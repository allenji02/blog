<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>[HBU]人工智能基础实验报告 - AllenJi&#39;s Blog</title><meta name="Description" content="AllenJi&#39;s Blog"><meta property="og:title" content="[HBU]人工智能基础实验报告" />
<meta property="og:description" content="作业 1-ML 基础 1、监督学习、无监督学习 监督学习：从标注数据种学习预测模型 无监督学习：从无标记的训练数据中推断结论 2、分类、回归 分类：将事务分成特" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/posts/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-14T19:35:31+08:00" />
<meta property="article:modified_time" content="2023-04-10T14:59:00+08:00" /><meta property="og:site_name" content="AllenJi&#39;s Blog" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[HBU]人工智能基础实验报告"/>
<meta name="twitter:description" content="作业 1-ML 基础 1、监督学习、无监督学习 监督学习：从标注数据种学习预测模型 无监督学习：从无标记的训练数据中推断结论 2、分类、回归 分类：将事务分成特"/>
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://example.org/posts/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[HBU]人工智能基础实验报告",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/example.org\/posts\/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A\/"
        },"genre": "posts","keywords": "HBU","wordcount":  9010 ,
        "url": "http:\/\/example.org\/posts\/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A\/","datePublished": "2023-03-14T19:35:31+08:00","dateModified": "2023-04-10T14:59:00+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "AllenJi"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="AllenJi&#39;s Blog">AllenJi&#39;s Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="AllenJi&#39;s Blog">AllenJi&#39;s Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">[HBU]人工智能基础实验报告</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>AllenJi</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2023-03-14">2023-03-14</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;9010 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;18 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#作业-1-ml-基础">作业 1-ML 基础</a></li>
    <li><a href="#作业-2-监督学习">作业 2-监督学习</a></li>
    <li><a href="#作业-3-监督学习">作业 3-监督学习</a></li>
    <li><a href="#作业-4-无监督学习">作业 4-无监督学习</a></li>
    <li><a href="#作业-5-深度学习基础">作业 5-深度学习基础</a></li>
    <li><a href="#作业-6-误差反向传播">作业 6-误差反向传播</a></li>
    <li><a href="#作业-7-卷积">作业 7-卷积</a></li>
    <li><a href="#作业-8-卷积-2">作业 8-卷积 2</a></li>
    <li><a href="#作业-9-卷积-3-xo-识别">作业 9-卷积 3-XO 识别</a></li>
    <li><a href="#作业-10-经典卷积网络">作业 10-经典卷积网络</a></li>
    <li><a href="#作业-11-rnn">作业 11-RNN</a></li>
    <li><a href="#作业-12-lstm">作业 12-LSTM</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><h2 id="作业-1-ml-基础">作业 1-ML 基础</h2>
<p><strong>1、监督学习、无监督学习</strong></p>
<p>监督学习：从标注数据种学习预测模型</p>
<p>无监督学习：从无标记的训练数据中推断结论</p>
<p><strong>2、分类、回归</strong></p>
<p>分类：将事务分成特定的类型</p>
<p>回归：建立变量之间的函数关系</p>
<p><strong>3、聚类、降维</strong></p>
<p>聚类：常见的无监督算法，让样本聚成不同的类型</p>
<p>降维：降低数据的维度，主成分分析就含有降维技术</p>
<p><strong>4、损失函数</strong></p>
<p>损失函数：描述实际值与预测值差距的一种函数</p>
<p><strong>5、训练集、测试集、验证集</strong></p>
<p>训练集：用来训练模型以及确定参数</p>
<p>验证集：用于确定网络结构以及调整模型的超参数，来确定是否需要继续训练</p>
<p>测试集：用于检验模型的泛化能力，测试集用来形容模型能力的好坏</p>
<p><strong>6、过拟合、欠拟合</strong></p>
<p>过拟合：训练过度，只对训练集的效果好，对测试集的效果差</p>
<p>欠拟合：训练的不够，对训练集和测试集的效果都差</p>
<p><strong>7、经验风险、期望风险</strong></p>
<p>经验风险：经验风险来源于训练数据集，训练数据集的平均损失也称为经验风险。</p>
<p>期望风险：期望风险针对的是全体数据。也就是已有的数据，未有的数据都包括在内。</p>
<h2 id="作业-2-监督学习">作业 2-监督学习</h2>
<p><strong>1、结构风险最小</strong></p>
<p>结构风险最小化等价于正则化</p>
<p><strong>2、正则化</strong></p>
<p>损失函数中对网络超参数加权，防止过拟合</p>
<p><strong>3、线性回归</strong></p>
<p>预测连续值</p>
<p><strong>4、逻辑斯蒂回归</strong></p>
<p>将值确定在[0,1]之间，分类用的</p>
<p><strong>5、Sigmoid 与 SoftMax 函数</strong></p>
<p>前者用于二分类 后者用于多分类
$$
g(x) ={1\over 1+e^{-z} }\\
softmax(x)=softmax(\begin{bmatrix}x_{1}  &amp; x_{2} &amp; &hellip; &amp; x_{n}\end{bmatrix} )=\begin{bmatrix}e^{x_{1}} \over {\textstyle \sum_{j}^{} e^{xj}}   &amp; e^{x_{2}} \over {\textstyle \sum_{j}^{} e^{xj}} &amp; &hellip; &amp; e^{x_{n}} \over {\textstyle \sum_{j}^{} e^{xj}}\end{bmatrix}
$$</p>
<p><strong>6、决策树</strong></p>
<p>是一种基本的分类与回归方法</p>
<p><strong>7、信息熵 条件熵 信息增益</strong></p>
<p>信息熵度量不确定性</p>
<p>条件熵度量某种条件下的不确定性</p>
<p>信息增益代表了某种条件下，原始变量不确定性的减小程度</p>
<p><strong>8、线性判别分析 LDA</strong></p>
<p>将高纬度的通过投影降维 从而分类</p>
<p><strong>9、PAC</strong></p>
<p>同等条件下，模型越复杂泛化误差越大。同一模型在样本满足一定条件的情况下，样本数量越大，模型泛化误差越小，因此还可以说模型越复杂越吃样本</p>
<p><strong>10、Adaboost</strong></p>
<p>针对同一个训练集训练不同的弱分类器，然后把这些弱分类器集合起来，构成一个更强的强分类器</p>
<h2 id="作业-3-监督学习">作业 3-监督学习</h2>
<p><strong>1、集成学习</strong></p>
<p>通过训练若干个个体学习器，通过一定的结合策略，来完成学习任务。</p>
<p><strong>2、支持向量机</strong></p>
<p>尝试拟合两个类别之间最宽的间距</p>
<p><strong>3、软间隔</strong></p>
<p>软间隔是一种支持向量机中的概念，允许一定程度的分类错误，以便在处理线性不可分数据时达到更好的分类效果。</p>
<p><strong>4、核函数</strong></p>
<p>让原本在低维空间中线性不可分的数据变得在高维空间中线性可分。常见的有
$$
线性核函数K(x,y)=x^{T}y\\
多项式核函数K(x,y)=(x^Ty+c)^d\\
多项式径向基函数核K(x,y)=exp(- {\left \| x-y \right \| ^2 \over 2\sigma ^2})
$$
<strong>5、VC 维</strong></p>
<p>度量机器学习算法的学习能力和泛化性能</p>
<p><strong>6、生成模型</strong></p>
<p>通过对观察数据的概率分布，生成与训练数据具有相似特征的新数据</p>
<p><strong>7、判别模型</strong></p>
<p>找到一个边界或者函数，以便根据输入数据准确地预测输出标签</p>
<p><strong>8、生成式模型和判别式模型优缺点</strong></p>
<p>生成式模型优点</p>
<ul>
<li>可以学习数据的概率分布</li>
<li>对数据的结构和关系有更深入的理解</li>
</ul>
<p>判别式模型优点</p>
<ul>
<li>
<p>预测性能较好</p>
</li>
<li>
<p>计算效率较高</p>
</li>
<li>
<p>一个的优点就是另一个的缺点</p>
</li>
</ul>
<p><strong>9、监督学习是判别式方法，无监督学习是生成式方法</strong></p>
<p>不正确，监督学习和无监督学习描述的是学习任务的类型，生成式方法和判别式方法描述的是模型的学习方式。</p>
<p><strong>10、分类是判别式方法，聚类是生成式方法？KNN，K-means 分别是什么方法？</strong></p>
<p>不正确，KNN 判别式，kmeans 生成式。</p>
<h2 id="作业-4-无监督学习">作业 4-无监督学习</h2>
<p><strong>1、K 均值聚类</strong></p>
<p>一种常用的无监督学习算法，基于数据点之间的距离来进行聚类，通过最小化簇内点到簇中心的距离的平方和来进行优化。</p>
<p><strong>2、K 均值聚类是生成式还是判别式方法</strong></p>
<p>不是生成式也不是判别式。</p>
<p><strong>3、KNN VS K-means</strong></p>
<ul>
<li>监督学习 vs 无监督学习：KNN 是一种监督学习算法，而 K-means 是一种无监督学习算法。</li>
<li>分类/回归 vs 聚类：KNN 用于分类和回归问题，而 K-means 用于聚类问题。</li>
<li>预测新数据点 vs 确定数据点的分组：KNN 用于预测新数据点的标签或数值，而 K-means 用于确定数据点的分组。</li>
<li>K 值的含义不同：在 KNN 中，K 代表要考虑的最近邻居的数量，而在 K-means 中，K 代表要将数据点分成的簇的数量。</li>
</ul>
<p><strong>4、主成分分析</strong></p>
<p>将高维数据映射到低维空间，从而实现对数据的降维和特征提取。</p>
<p><strong>5、LDA VS PCA</strong></p>
<ul>
<li>LDA 让映射后的样本有最好的分类性能。</li>
<li>PCA 让映射后的样本有最大的发散性。</li>
</ul>
<p><strong>6、奇异值分解（SVD）</strong></p>
<p>对于一个 $m \times n$ 的实矩阵 $A$，它的奇异值分解为：
$$
A=U Σ V^T
$$
其中，$U$ 是 $m \times n$ 的正交矩阵，$V$ 是 $n \times n$ 的正交矩阵，$Σ$ 是 $m \times n$ 的对角矩阵，对角线上的元素 $\sigma_{1},\sigma_{2}  , \cdots,\sigma_{r}  $ 称为 $A$ 的奇异值 $r = min(m,n)$。$Σ$ 的其余元素都是零。</p>
<p>具体来说，$U$ 和 $V$ 的列向量是 $AA^T$ 和 $A^TA$ 的特征向量，$Σ$ 的对角线元素是 $AA^T$ 和 $A^TA$ 的非零特征值的平方根。</p>
<p><strong>7、特征人脸方法（Eigenface）</strong></p>
<p>基于奇异值分解（SVD）的思想，通过计算训练集中人脸图像的主成分，从而得到一组人脸特征向量，这些特征向量被称为 Eigenface。</p>
<p><strong>8、潜在语义分析（LSA）</strong></p>
<p>基于奇异值分解（SVD）的文本挖掘技术，它通过将文本转化为向量空间模型，利用矩阵分解技术找到文本语义的潜在结构，从而实现文本的自动分类、聚类和相似性计算。</p>
<p><strong>9、期望最大化算法（EM）</strong></p>
<p>一种常用的统计学习算法，用于估计包含隐变量的概率模型的参数。它通过迭代的方式，交替进行两个步骤：E 步骤和 M 步骤，从而不断更新模型参数，直到收敛。</p>
<p><strong>10、K-means 是最简单的 EM 算法</strong></p>
<p>可以说 K-means 是 EM 算法的一种特殊情况，它可以看作是最简单的 EM 算法之一，但并不完全等同于 EM 算法。</p>
<p><strong>11、编程实现 EM 算法</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">math</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">cal_mu</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">xi</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">w</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">xi</span><span class="p">)</span> <span class="o">/</span> \
</span></span><span class="line"><span class="cl">           <span class="nb">float</span><span class="p">(</span><span class="n">w</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">xi</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                 <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">w</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">q</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">xi</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">e_step</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">mu</span> <span class="o">=</span> <span class="p">[</span><span class="n">cal_mu</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span> <span class="k">for</span> <span class="n">xi</span> <span class="ow">in</span> <span class="n">x</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">mu</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">m_step</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">w</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">p</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="p">))])</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">q</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="p">))])</span> <span class="o">/</span> \
</span></span><span class="line"><span class="cl">        <span class="nb">sum</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mu</span><span class="p">))])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">maxiteration</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiteration</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">mu</span> <span class="o">=</span> <span class="n">e_step</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">]</span> <span class="o">==</span> <span class="n">m_step</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">]</span> <span class="o">=</span> <span class="n">m_step</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">([</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="p">[</span><span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">run</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="作业-5-深度学习基础">作业 5-深度学习基础</h2>
<p><strong>1、人工智能、机器学习、深度学习之间的关系</strong></p>
<ul>
<li>
<p>人工智能是一种广义的概念。</p>
</li>
<li>
<p>机器学习是一种实现人工智能的技术。</p>
</li>
<li>
<p>深度学习是一种机器学习的子领域，它使用深度神经网络来实现自动化学习和预测分析。</p>
</li>
</ul>
<p><strong>2、神经网络与深度学习的关系</strong></p>
<ul>
<li>神经网络是一种数学模型，它由一个或多个神经元组成，可以通过对输入数据的处理来进行分类、回归或者聚类等任务。</li>
<li>深度学习则是基于神经网络的一种特殊形式，它是一种通过组合多个神经元层来构建更加复杂的模型，从而实现对大规模数据进行学习和推断的方法。</li>
</ul>
<p><strong>3、深度学习和传统浅层学习的区别和联系</strong></p>
<ul>
<li>传统浅层学习是指传统的机器学习方法,深度学习采用深度神经网络来实现自动化学习和预测分析。</li>
<li>在联系方面，深度学习和传统浅层学习都是机器学习的分支，都是使用数据来进行预测和分类的。</li>
</ul>
<p><strong>4、神经元、人工神经元</strong></p>
<ul>
<li>神经元是生物学中的一种细胞，是神经系统的基本功能单元。</li>
<li>人工神经元是一种数学模型，它模仿了生物神经元的结构和功能，可以接收输入信号、处理信息、产生输出信号。人工神经元通常由多个输入端口和一个输出端口组成。</li>
</ul>
<p><strong>5、MP 模型</strong></p>
<p>MP 模型的神经元有两种状态，分别为激活（active）和抑制（inactive）状态。当神经元接收到的输入信号超过了一个阈值时，它就会被激活，产生一个输出信号，否则它就处于抑制状态，不产生输出信号。</p>
<p><strong>6、单层感知机 SLP</strong></p>
<p>单层感知机是一种最早的神经网络模型之一，基于线性分类器的模型，可以用于解决二分类问题。</p>
<p><strong>7、异或问题 XOR</strong></p>
<p>异或问题是一个在传统浅层神经网络中无法解决的问题。解决异或问题的方法是使用多层神经网络，比如多层感知机。</p>
<p><strong>8、多层感知机 MLP</strong></p>
<p>多层感知机是一种前馈神经网络，由多个神经网络层组成，其中每个神经网络层都由多个神经元组成。</p>
<p><strong>9、前馈神经网络 FNN</strong></p>
<p>前馈神经网络是一种最基本的神经网络模型，也被称为多层感知机。</p>
<p><strong>10、激活函数 Activation Function</strong></p>
<p>在神经网络中，激活函数是将神经元的输入信号转换为输出信号的非线性函数。</p>
<p><strong>11、为什么要使用激活函数？</strong></p>
<ul>
<li>引入非线性特性</li>
<li>增强神经网络的表达能力</li>
<li>提高模型的稳定性</li>
<li>梯度下降算法的实现</li>
</ul>
<p><strong>12、常用激活函数有哪些？</strong></p>
<ul>
<li>sigmoid 函数：$f(x)=\frac{1}{1+e^{-x}}$</li>
<li>ReLU  函数：$f(x)=max(0,x)$</li>
<li>tanh 函数：$f(x)=\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$</li>
</ul>
<p><strong>13、均方误差和交叉熵损失函数，哪个适合于分类？哪个适合于回归？为什么？</strong></p>
<p>对于分类问题，通常使用交叉熵损失函数，对于回归问题，通常使用均方误差损失函数。</p>
<p>交叉熵损失函数适合于分类问题，特别是多分类问题。它的优点是可以有效地处理分类问题中的概率分布，而且当预测结果与真实结果差距较大时，损失函数的值会迅速增大，从而更容易发现错误。此外，交叉熵损失函数的梯度计算也比较简单，便于优化算法的实现。</p>
<p>均方误差损失函数适合于回归问题，特别是对于数值预测问题，它可以测量预测值与真实值之间的平方差，因此可以使得预测值尽可能地接近真实值。此外，均方误差损失函数也可以很好地处理离群值，因为它对预测误差的平方进行求和，因此离群值的影响相对较小。</p>
<h2 id="作业-6-误差反向传播">作业 6-误差反向传播</h2>
<p><strong>1、梯度下降</strong></p>
<p>梯度下降是一种用于优化函数的迭代算法，通常用于训练机器学习模型。其核心思想是通过迭代的方式逐步调整模型参数，使得损失函数的值不断减小，从而使得模型的预测结果更加准确。</p>
<p><strong>2、反向传播</strong></p>
<p>反向传播是一种用于计算神经网络中权重和偏置梯度的算法，通常与梯度下降一起使用来训练神经网络。</p>
<p><strong>3、计算图</strong></p>
<p>计算图是一种用于表示数学运算的图形化表示法，它通常用于机器学习和深度学习中。计算图由节点和边组成，其中节点表示数学运算，边表示数据流动。</p>
<p><strong>4、使用 numpy 编程实现例题</strong></p>
<p><strong>4.1 初始化</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">initialize_parameters</span><span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_h</span><span class="p">,</span> <span class="n">n_y</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()))</span>
</span></span><span class="line"><span class="cl">    <span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_h</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
</span></span><span class="line"><span class="cl">    <span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_h</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_y</span><span class="p">,</span> <span class="n">n_h</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
</span></span><span class="line"><span class="cl">    <span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;W1&#34;</span><span class="p">:</span> <span class="n">W1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                  <span class="s2">&#34;b1&#34;</span><span class="p">:</span> <span class="n">b1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                  <span class="s2">&#34;W2&#34;</span><span class="p">:</span> <span class="n">W2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                  <span class="s2">&#34;b2&#34;</span><span class="p">:</span> <span class="n">b2</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">parameters</span>
</span></span></code></pre></div><p><strong>4.2 正向传播模块</strong></p>
<p><strong>4.2.1 线性正向</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">linear_forward</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>
</span></span><span class="line"><span class="cl">    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cache</span>
</span></span></code></pre></div><p><strong>4.2.2 正向线性激活</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">linear_activation_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&#34;sigmoid&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">Z</span><span class="p">,</span> <span class="n">linear_cache</span> <span class="o">=</span> <span class="n">linear_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">A</span><span class="p">,</span> <span class="n">activation_cache</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&#34;relu&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">Z</span><span class="p">,</span> <span class="n">linear_cache</span> <span class="o">=</span> <span class="n">linear_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">A</span><span class="p">,</span> <span class="n">activation_cache</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">linear_cache</span><span class="p">,</span> <span class="n">activation_cache</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">cache</span>
</span></span></code></pre></div><p><strong>4.3 损失函数</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">compute_cost</span><span class="p">(</span><span class="n">AL</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">/</span> <span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">AL</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">AL</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">cost</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">cost</span>
</span></span></code></pre></div><p><strong>4.4 反向传播模块</strong></p>
<p><strong>4.4.1 线性反向</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">linear_backward</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">cache</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">cache</span>
</span></span><span class="line"><span class="cl">    <span class="n">m</span> <span class="o">=</span> <span class="n">A_prev</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">dW</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">A_prev</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">db</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">dA_prev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dZ</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dA_prev</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span>
</span></span></code></pre></div><p><strong>4.4.2 反向线性激活</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">linear_activation_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">cache</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">linear_cache</span><span class="p">,</span> <span class="n">activation_cache</span> <span class="o">=</span> <span class="n">cache</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&#34;relu&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">dZ</span> <span class="o">=</span> <span class="n">relu_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">activation_cache</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">dA_prev</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">linear_backward</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">linear_cache</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">activation</span> <span class="o">==</span> <span class="s2">&#34;sigmoid&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">dZ</span> <span class="o">=</span> <span class="n">sigmoid_backward</span><span class="p">(</span><span class="n">dA</span><span class="p">,</span> <span class="n">activation_cache</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">dA_prev</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span> <span class="o">=</span> <span class="n">linear_backward</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">linear_cache</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dA_prev</span><span class="p">,</span> <span class="n">dW</span><span class="p">,</span> <span class="n">db</span>
</span></span></code></pre></div><p><strong>4.4.3 更新参数</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">update_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">L</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">parameters</span><span class="p">[</span><span class="s2">&#34;W&#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&#34;W&#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&#34;dW&#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">        <span class="n">parameters</span><span class="p">[</span><span class="s2">&#34;b&#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&#34;b&#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&#34;db&#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">parameters</span>
</span></span></code></pre></div><p><strong>5、使用 PyTorch 的 Backward() 编程实现例题</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">y_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.0</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">LinearModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">y_pred</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">LinearModel</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;w = &#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b = &#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">x_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">4.0</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">y_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y_pred = &#39;</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="作业-7-卷积">作业 7-卷积</h2>
<p><strong>1、简单描述卷积、卷积核、多通道、特征图、特征选择概念</strong></p>
<ul>
<li>
<p>卷积：卷积核与输入数据进行按元素相乘并求和的操作。</p>
</li>
<li>
<p>卷积核：卷积核是一个小型矩阵，用于在卷积过程中与输入数据进行逐元素相乘并求和的操作。</p>
</li>
<li>
<p>多通道：多通道是指输入数据具有多个维度。</p>
</li>
<li>
<p>特征图：特征图是卷积操作后得到的输出数据。</p>
</li>
<li>
<p>特征选择：特征选择是机器学习中一种降低模型复杂度、提高泛化能力的方法。</p>
</li>
</ul>
<p><strong>2、边缘检测</strong></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./1_origin.png"
        data-srcset="./1_origin.png, ./1_origin.png 1.5x, ./1_origin.png 2x"
        data-sizes="auto"
        alt="./1_origin.png"
        title="./1_origin.png" /></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SimHei&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.unicode_minus&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl"><span class="n">file_path</span> <span class="o">=</span> <span class="s1">&#39;Cameraman.tif&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s1">&#39;L&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;uint8&#39;</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;原图&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">im</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">im</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span>
</span></span><span class="line"><span class="cl"><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">sobel_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="c1"># 卷积核</span>
</span></span><span class="line"><span class="cl"><span class="n">sobel_kernel</span> <span class="o">=</span> <span class="n">sobel_kernel</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">sobel_kernel</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">edge1</span> <span class="o">=</span> <span class="n">conv1</span><span class="p">(</span><span class="n">Variable</span><span class="p">(</span><span class="n">im</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">edge1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">edge1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">edge1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">255</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">edge1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">edge1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">edge1</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">edge1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./1_post.png"
        data-srcset="./1_post.png, ./1_post.png 1.5x, ./1_post.png 2x"
        data-sizes="auto"
        alt="./1_post.png"
        title="./1_post.png" /></p>
<p><strong>3、锐化</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sobel_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./2_post.png"
        data-srcset="./2_post.png, ./2_post.png 1.5x, ./2_post.png 2x"
        data-sizes="auto"
        alt="./2_post.png"
        title="./2_post.png" /></p>
<p><strong>4、模糊</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sobel_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0625</span><span class="p">,</span> <span class="mf">0.125</span><span class="p">,</span> <span class="mf">0.0625</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span><span class="mf">0.125</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.125</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span><span class="mf">0.0625</span><span class="p">,</span> <span class="mf">0.125</span><span class="p">,</span><span class="mf">0.0625</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
</span></span></code></pre></div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./3_post.png"
        data-srcset="./3_post.png, ./3_post.png 1.5x, ./3_post.png 2x"
        data-sizes="auto"
        alt="./3_post.png"
        title="./3_post.png" /></p>
<h2 id="作业-8-卷积-2">作业 8-卷积 2</h2>
<p><strong>1、步长、填充</strong></p>
<ul>
<li>步长（stride）：在卷积神经网络中，步长表示滤波器（卷积核）在输入数据上滑动的距离。</li>
<li>填充（padding）：在卷积神经网络中，填充是在输入数据周围添加额外的“像素”或“值”，以便在应用卷积核时保持输入和输出的尺寸。</li>
</ul>
<p><strong>2、感受野</strong></p>
<p>感受野是指输出特征图中一个神经元所对应的输入数据区域</p>
<p><strong>3、局部感知、权值共享</strong></p>
<ul>
<li>局部感知是指在卷积神经网络中，神经元只对其输入的一小部分区域做出响应</li>
<li>权值共享是指在卷积神经网络中，多个神经元共享同一组参数，这个参数组被称为卷积核</li>
</ul>
<p><strong>4、池化（子采样、降采样、汇聚）</strong></p>
<p>是卷积神经网络中的一种操作。它通常紧跟在卷积层后面，用于减小特征图（Feature Map）的尺寸和数量，同时保留输入数据的重要特征。</p>
<p><strong>5、低级特征、中级特征、高级特征</strong></p>
<ul>
<li>
<p>低级特征通常指一些较为基础的、直接从原始数据中提取的特征，如颜色、纹理、边缘等，它们通常对于物体的分类或识别任务并不十分有效，但是可以作为中级特征的基础。</p>
</li>
<li>
<p>中级特征则是指基于低级特征构建的一些更高层次的特征，如形状、轮廓、纹理组合等，这些特征能够更好地描述物体的形态和结构，因此对于分类或识别任务的效果会更好。</p>
</li>
<li>
<p>高级特征则是指基于中级特征构建的更加抽象和复杂的特征，如物体的部件、结构、语义等，这些特征能够更好地描述物体的高层次语义信息，因此对于更加复杂的任务（如目标检测、语义分割等）的效果会更好。</p>
</li>
</ul>
<h2 id="作业-9-卷积-3-xo-识别">作业 9-卷积 3-XO 识别</h2>
<p><strong>Code：</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;font.sans-serif&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;SimHei&#39;</span><span class="p">]</span>  <span class="c1"># 用来正常显示中文标签</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.unicode_minus&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># 用来正常显示负号 #有中文出现的情况，需要u&#39;内容</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 将输出转换为图片的格式</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;原图&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;--------------- 卷积  ---------------&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># in_channel , out_channel , kennel_size , stride</span>
</span></span><span class="line"><span class="cl"><span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">                                   <span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">conv1</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 将输出转换为图片的格式</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Kernel 1&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># in_channel , out_channel , kennel_size , stride</span>
</span></span><span class="line"><span class="cl"><span class="n">conv2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">                                   <span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">conv2</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 将输出转换为图片的格式</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Kernel 2&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">conv3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># in_channel , out_channel , kennel_size , stride</span>
</span></span><span class="line"><span class="cl"><span class="n">conv3</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[[[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">                                   <span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">conv3</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 将输出转换为图片的格式</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Kernel 3&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">feature_map1</span> <span class="o">=</span> <span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_map2</span> <span class="o">=</span> <span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_map3</span> <span class="o">=</span> <span class="n">conv3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_map1</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_map2</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_map3</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">feature_map1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 将输出转换为图片的格式</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;卷积后的特征图1&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;--------------- 池化  ---------------&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">max_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Pooling</span>
</span></span><span class="line"><span class="cl"><span class="n">zeroPad</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ZeroPad2d</span><span class="p">(</span><span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># pad 0 , Left Right Up Down</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">feature_map_pad_0_1</span> <span class="o">=</span> <span class="n">zeroPad</span><span class="p">(</span><span class="n">feature_map1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_pool_1</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">feature_map_pad_0_1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_map_pad_0_2</span> <span class="o">=</span> <span class="n">zeroPad</span><span class="p">(</span><span class="n">feature_map2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_pool_2</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">feature_map_pad_0_2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_map_pad_0_3</span> <span class="o">=</span> <span class="n">zeroPad</span><span class="p">(</span><span class="n">feature_map3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_pool_3</span> <span class="o">=</span> <span class="n">max_pool</span><span class="p">(</span><span class="n">feature_map_pad_0_3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_pool_1</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_pool_1</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_pool_2</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_pool_3</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">feature_pool_1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 将输出转换为图片的格式</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;卷积池化后的特征图1&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;--------------- 激活  ---------------&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">activation_function</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">feature_relu1</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">(</span><span class="n">feature_map1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_relu2</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">(</span><span class="n">feature_map2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">feature_relu3</span> <span class="o">=</span> <span class="n">activation_function</span><span class="p">(</span><span class="n">feature_map3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_relu1</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_relu2</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">feature_relu3</span> <span class="o">/</span> <span class="mi">9</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">img</span> <span class="o">=</span> <span class="n">feature_relu1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 将输出转换为图片的格式</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;卷积 + relu 后的特征图1&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></div><p><strong>Output：</strong></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./exp9/origin.png"
        data-srcset="./exp9/origin.png, ./exp9/origin.png 1.5x, ./exp9/origin.png 2x"
        data-sizes="auto"
        alt="./exp9/origin.png"
        title="./exp9/origin.png" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./exp9/kernel_1.png"
        data-srcset="./exp9/kernel_1.png, ./exp9/kernel_1.png 1.5x, ./exp9/kernel_1.png 2x"
        data-sizes="auto"
        alt="./exp9/kernel_1.png"
        title="./exp9/kernel_1.png" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./exp9/kernel_2.png"
        data-srcset="./exp9/kernel_2.png, ./exp9/kernel_2.png 1.5x, ./exp9/kernel_2.png 2x"
        data-sizes="auto"
        alt="./exp9/kernel_2.png"
        title="./exp9/kernel_2.png" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./exp9/kernel_3.png"
        data-srcset="./exp9/kernel_3.png, ./exp9/kernel_3.png 1.5x, ./exp9/kernel_3.png 2x"
        data-sizes="auto"
        alt="./exp9/kernel_3.png"
        title="./exp9/kernel_3.png" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./exp9/feature_1.png"
        data-srcset="./exp9/feature_1.png, ./exp9/feature_1.png 1.5x, ./exp9/feature_1.png 2x"
        data-sizes="auto"
        alt="./exp9/feature_1.png"
        title="./exp9/feature_1.png" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./exp9/feature_2.png"
        data-srcset="./exp9/feature_2.png, ./exp9/feature_2.png 1.5x, ./exp9/feature_2.png 2x"
        data-sizes="auto"
        alt="./exp9/feature_2.png"
        title="./exp9/feature_2.png" /></p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="./exp9/feature_3.png"
        data-srcset="./exp9/feature_3.png, ./exp9/feature_3.png 1.5x, ./exp9/feature_3.png 2x"
        data-sizes="auto"
        alt="./exp9/feature_3.png"
        title="./exp9/feature_3.png" /></p>
<h2 id="作业-10-经典卷积网络">作业 10-经典卷积网络</h2>
<p><strong>LeNet &amp; MNIST</strong></p>
<p>LeNet 是由 Yann LeCun 及其合作者于 1998 年开发的一种具有开创性的卷积神经网络架构。它的设计目的是识别手写数字并执行图像分类任务。MNIST 是一个用于手写数字识别的大型数据库，常被用于训练图像处理系统。LeNet 与 MNIST 的关系在于，LeNet 经常被用于 MNIST 数据集的训练和测试。</p>
<p><strong>AlexNet &amp; CIFAR</strong></p>
<p>AlexNet 是由 Alex Krizhevsky，Ilya Sutskever 和 Geoffrey Hinton 在2012年开发的深度卷积神经网络架构。AlexNet 包含多个卷积层、池化层、全连接层和激活函数，并引入了 Dropout 技术以减少过拟合现象。CIFAR 是一个包含两个子数据集的图像分类数据库：CIFAR-10 和 CIFAR-100。尽管 AlexNet 最初是针对 ImageNet 数据集开发的，但它的架构和训练方法也可以应用于其他图像分类任务，如CIFAR 数据集。</p>
<p><strong>VGG Net</strong></p>
<p>VGG Net 是一种深度卷积神经网络架构，由 Oxford University 的 Visual Geometry Group（VGG）团队于2014年开发。VGG Net 在当年的 ImageNet 大规模视觉识别挑战（ILSVRC）中取得了优异成绩，以其简洁的结构和卓越的性能获得了广泛关注。VGG Net 的核心思想是通过使用较小的卷积核（如3x3）和多个连续卷积层来增加网络深度，从而提高模型的表达能力。VGG Net 有多个版本，如 VGG-16和 VGG-19，这些数字代表网络中包含的权重层（卷积层和全连接层）的数量。</p>
<p><strong>GoogLeNet &amp; Inception v1</strong></p>
<p>GoogLeNet 是一种深度卷积神经网络架构，由 Google 的研究人员于2014年开发。GGoogLeNet 的核心创新是引入了一种名为 Inception 的模块结构，因此 GoogLeNet 有时也被称为 Inception v1。Inception 模块的主要思想是将多个卷积核大小的卷积层和池化层并行堆叠，从而在不同尺度上捕捉图像特征。具体而言，Inception 模块包含 1x1、3x3、5x5 的卷积层（加入 1x1 卷积层进行降维以减少计算量）和 3x3 最大池化层。这些层在同一级别并行操作，然后将它们的输出连接起来，形成一个更丰富的特征表示。</p>
<p><strong>ResNet</strong></p>
<p>ResNet（Residual Network）是由 Kaiming He, Xiangyu Zhang, Shaoqing Ren 和 Jian Sun 于 2015 年提出的一种深度卷积神经网络架构。ResNet 在 2015 年的 ImageNet 大规模视觉识别挑战（ILSVRC）中获得了冠军，同时在分类、定位、检测和分割等任务上取得了前所未有的成绩。ResNet 的关键创新是引入残差连接（residual connections）来解决深度神经网络中的梯度消失和退化问题。</p>
<h2 id="作业-11-rnn">作业 11-RNN</h2>
<p><strong>1、前馈网络存在的问题</strong></p>
<ul>
<li>
<p>梯度消失/梯度爆炸问题：在深度前馈网络中，当使用如sigmoid或tanh等饱和性激活函数时，网络在训练过程中可能会出现梯度消失的问题。这就导致了网络参数很难更新，进而影响网络的学习。相反，如果梯度过大，则可能会导致梯度爆炸，使得网络训练变得不稳定。</p>
</li>
<li>
<p>过拟合问题：前馈网络可能会过度拟合训练数据，这就使得网络在新的、未见过的数据上表现得不好。这个问题可以通过正则化技术，如权重衰减、Dropout等方法来缓解。</p>
</li>
<li>
<p>不能处理时序数据：前馈网络无法处理时序数据或者序列数据，因为它们没有记忆功能，无法保存先前的状态或输出。这对于理解语音、文本等顺序数据非常重要。而这一点可以通过引入RNN或LSTM等模型来解决。</p>
</li>
</ul>
<p><strong>2、序列数据</strong></p>
<p>序列数据是一种数据类型，其中的元素存在特定的顺序。</p>
<p><strong>3、循环神经网络（RNN）为什么能解决前馈网络中的问题</strong></p>
<ul>
<li>处理变长序列：RNN通过在序列的每个元素上一次处理一个元素来操作。这就意味着它可以处理任何长度的序列。</li>
<li>获取时间/空间的上下文信息：RNN的核心思想是有一个循环的隐藏状态，这个隐藏状态可以保存并更新过去的信息。因此，RNN在处理当前输入时，可以利用隐藏状态获取过去的信息。</li>
</ul>
<p><strong>4、卷积神经网络（CNN）与循环神经网络（RNN）的异同</strong></p>
<p>相同点：</p>
<ul>
<li>深度学习模型：CNN和RNN都是深度学习的模型，使用了神经网络的结构，并通过反向传播和梯度下降等优化算法进行训练。</li>
<li>非线性映射：它们都可以学习输入和输出之间的复杂非线性映射。</li>
<li>参数共享：CNN和RNN都使用参数共享的策略。CNN在所有空间位置共享其核的参数，RNN在时间步骤中共享其参数。</li>
</ul>
<p>不同点：</p>
<ul>
<li>数据类型：CNN主要用于处理网格型数据，如图像和音频。RNN主要处理序列数据，如时间序列和文本。</li>
<li>结构：CNN有卷积层和池化层，主要用于局部感知和降维。RNN有循环层，可以处理序列数据，能够在时间步骤中传递信息。</li>
<li>空间/时间依赖性：CNN通过使用卷积核来学习局部特征，适合于处理固定长度的输入（如固定大小的图像），对空间依赖性有很好的处理能力。RNN可以处理任何长度的序列，对于长期的时间依赖性，标准的RNN处理起来有困难，但LSTM或GRU等RNN的变体可以很好地解决这个问题。</li>
<li>并行计算：CNN的前向和后向传播都可以高效地并行化，因为其卷积操作在所有位置都是独立的。但RNN由于其序列依赖性，在时间步骤上难以进行有效的并行化。</li>
</ul>
<p><strong>5、沿时间反向传播算法（BPTT）</strong></p>
<p>沿时间反向传播（Backpropagation Through Time, BPTT）是一种用于训练循环神经网络（RNN）的方法。它是标准反向传播算法的一个特例，适用于具有循环（即反馈连接）的网络。</p>
<p><strong>6、序列到序列模型 seq2seq</strong></p>
<p>序列到序列模型是一种在深度学习中用于生成序列的模型，特别适用于那些输入和输出都是序列的问题，如机器翻译、语音识别、文本摘要等。由编码器和解码器两部分组成。</p>
<p><strong>7、梯度消失、梯度爆炸</strong></p>
<p>梯度消失：当网络深度增加时，网络中的梯度可能会变得非常小。这意味着在反向传播过程中，当梯度传播到靠近输入层的网络部分时，它们的值可能已经变得非常接近于零。结果是，这些层的权重几乎没有更新，使得训练过程变得非常慢或者完全停止。</p>
<p>梯度爆炸：与梯度消失相反，梯度爆炸是指在训练过程中，梯度变得非常大，这会导致权重更新过大，使得网络不稳定。</p>
<h2 id="作业-12-lstm">作业 12-LSTM</h2>
<p><strong>长短期记忆网络 LSTM（输入门、遗忘门、输出门）</strong></p>
<p>长短期记忆网络是一种特殊的递归神经网络，它通过特别设计的网络结构来解决普通RNN在处理长序列数据时的梯度消失和爆炸问题。</p>
<ul>
<li>输入门（Input Gate）：决定我们要在记忆细胞中存储多少来自输入的新信息。它由两部分组成，一个是sigmoid层，另一个是tanh层。sigmoid层输出0到1之间的值，表示我们要保存多少新信息，0表示“什么都不保存”，1表示“保存所有”，而tanh层则生成新的候选值，可能会被加入到状态中。</li>
<li>遗忘门（Forget Gate）：决定我们要从记忆细胞中遗忘多少信息。它的作用是通过丢弃不再需要的信息，来保持细胞状态的有效性和简洁性。它是一个sigmoid层，输出0到1之间的值，0表示“完全忘记”，1表示“完全记住”。</li>
<li>输出门（Output Gate）：根据当前输入和细胞状态，决定输出多少细胞的新状态。它由一个sigmoid层和一个tanh层组成。sigmoid层决定我们要输出哪部分信息，而tanh层则将细胞状态转换到-1到1之间，然后与sigmoid的输出相乘，最后输出我们想要的信息。</li>
</ul>
<p><strong>LSTM 如何克服梯度消失</strong></p>
<p>LSTM 在计算过程中，会有一条“细胞状态”直接在各个时间步之间传递。在每个时间步，都会有一些信息被遗忘，一些新信息被添加进来。这个过程通过“遗忘门”和“输入门”来控制。因为细胞状态的这种线性传递性，使得LSTM能够在一定程度上避免梯度消失问题。</p>
<p><strong>门控循环单元神经网络 GRU（更新门、重置门）</strong></p>
<p>GRU 网络主要有两个门，即更新门和重置门：</p>
<ul>
<li>更新门（Update Gate）：更新门帮助模型决定何时“忘记”以前的隐藏状态，何时使用新的候选隐藏状态。更新门的值越接近1，模型就越倾向于保留以前的隐藏状态；更新门的值越接近0，模型就越倾向于使用新的候选隐藏状态。更新门的设计帮助GRU捕捉和存储长序列中的依赖关系。</li>
<li>重置门（Reset Gate）：重置门帮助模型决定在计算新的候选隐藏状态时，是否要“忽视”以前的隐藏状态。重置门的值越接近1，模型就越倾向于“考虑”以前的隐藏状态；重置门的值越接近0，模型就越倾向于“忽视”以前的隐藏状态。重置门的设计使得GRU可以在不同程度上利用以前的隐藏状态，有助于捕捉序列中的复杂模式。</li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2023-04-10</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="http://example.org/posts/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" data-title="[HBU]人工智能基础实验报告" data-hashtags="HBU"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://example.org/posts/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" data-hashtag="HBU"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="http://example.org/posts/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" data-title="[HBU]人工智能基础实验报告"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="http://example.org/posts/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" data-title="[HBU]人工智能基础实验报告"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="http://example.org/posts/hbu%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9F%BA%E7%A1%80%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/" data-title="[HBU]人工智能基础实验报告"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/hbu/">HBU</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.111.3">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">AllenJi</a></span><span class="icp-splitter">&nbsp;|&nbsp;</span><br class="icp-br"/>
                    <span class="icp"><a href='https://beian.miit.gov.cn/#/Integrated/index' rel='noopener' target='_blank'>冀ICP备2020025647号</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
